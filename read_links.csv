#!/bin/bash

filename="data.csv"
declare -A profiles

while IFS=',' read -r title url
do
	title="${title//\"/}"
	url="${url//\"/}"
	profiles["$title"]="$url"
done < "$filename"

if ! [ -d data ]
	then
		mkdir data
fi
if ! [ -d data/rawdata ]
	then
		mkdir data/rawdata
fi
if ! [ -d data/sortdata ]
	then
		mkdir data/sortdata
fi

for key in "${!profiles[@]}"; do
	search=${profiles[$key]}
                #Extraer la informaciÃ³n de los posts de donde vienen los perfiles

	echo "###################################"
        echo "Analyzing Information From: $search"
        echo "###################################"

        search_limpia=$(echo "$search" | sed -e 's#https://www.instagram.com/##')
        echo "profile: $key"
        echo "link: $search_limpia"
        filename=$(echo "$key" | tr ' ' '_')
        wget --wait=40 --limit-rate=40k -U Mozilla -bq https://www.picnob.com/profile/$search_limpia/ -O data/rawdata/Ig-$filename.txt > /dev/null
        sleep 15
        while read -r linea; do
#Segunda parte
#Verificar si el texto coincide con alguna de las de los #'s de alguna empresa
		echo "$linea"
        done < data/rawdata/Ig-$filename.txt | grep  -o '<img alt[^>]*>' | tail -n +4 | head -n -1 | sed 's/class="lazyload[^>]*>//g' | sed 's/<img alt=//g' > data/sortdata/text-$filename.csv
	while read -r dates; do
		echo "$dates"
	done < data/rawdata/Ig-$filename.txt | grep '<span class="txt">' | head -n -1 | tail -n +2 | sed 's/<span class="txt">//g' | sed 's/<\/span>//g' > data/sortdata/dates-$filename.csv
	while read -r link; do
		echo "$link"
	done < data/rawdata/Ig-$filename.txt | grep 'data-src' | sed 's/.*data-src/data-src/' | sed 's/">//g' | sed 's/data-src="//g' > data/sortdata/links-$filename.csv
	text_data="data/sortdata/text-$filename.csv"
	text_list=()
	dates_data="data/sortdata/dates-$filename.csv"
	dates_list=()
	links_data="data/sortdata/links-$filename.csv"
	links_list=()
	while IFS= read -r text; do
		text_list+=("$text")
	done < "$text_data" 
	while IFS= read -r date; do
		IFS=',' read -ra fields2 <<< "$date"
		dates_list+=("${fields2[@]}")
	done < "$dates_data"
	while IFS= read -r link; do
		IFS=',' read -ra fields3 <<< "$link"
		links_list+=("${fields3[@]}")
	done < "$links_data"
	num_text_list=${#text_list[@]}
	num_dates_list=${#dates_list[@]}
	num_links_list=${#links_list[@]}
	echo "$num_text_list, $num_dates_list, $num_links_list"
	if [ $num_text_list -eq $num_dates_list ]; then
		if [ $num_text_list -eq $num_links_list ]; then
			for ((i = 0; i < num_text_list; i++)); do
				match_name="match_$((i+1))"
				line="${text_list[i]},${dates_list[i]},${links_list[i]}"
				echo "$line" >> "match-$filename.csv"
			done	
		else
			echo "los elementos del texto y los links no coinciden"
		fi
	else
		echo "los elementos del texto y los dates no coinciden"
	fi

done
